{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-Cy0MgcW2W"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ENHANCED OIL SPILL DETECTION - PROFESSIONAL VERSION\n",
        "# Target: 95-96% Accuracy with Comprehensive Visualizations\n",
        "# Hardware: T4 GPU Optimized\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "## CELL 1: Mount Drive\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__SRE55YYuCf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 2: ENHANCED SETUP WITH OPTIMIZATIONS\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, precision_recall_curve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# UPGRADE 1: Enable mixed precision for T4 GPU\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# UPGRADE 2: Configure GPU memory growth to prevent OOM\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✓ GPU Configured: {gpus}\")\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Mixed Precision:\", policy.compute_dtype)\n",
        "\n",
        "# Dataset Configuration\n",
        "BASE_DATA_DIR = '/content/drive/MyDrive/Dataset/dataset'\n",
        "TRAIN_DIR = os.path.join(BASE_DATA_DIR, 'train')\n",
        "VAL_DIR = os.path.join(BASE_DATA_DIR, 'val')\n",
        "TEST_DIR = os.path.join(BASE_DATA_DIR, 'test')\n",
        "\n",
        "TRAIN_IMAGES = os.path.join(TRAIN_DIR, 'images')\n",
        "TRAIN_MASKS = os.path.join(TRAIN_DIR, 'masks')\n",
        "VAL_IMAGES = os.path.join(VAL_DIR, 'images')\n",
        "VAL_MASKS = os.path.join(VAL_DIR, 'masks')\n",
        "TEST_IMAGES = os.path.join(TEST_DIR, 'images')\n",
        "TEST_MASKS = os.path.join(TEST_DIR, 'masks')\n",
        "\n",
        "# Verify directories\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DIRECTORY VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "for dir_path, dir_name in [(TRAIN_IMAGES, 'Train Images'),\n",
        "                             (TRAIN_MASKS, 'Train Masks'),\n",
        "                             (VAL_IMAGES, 'Val Images'),\n",
        "                             (VAL_MASKS, 'Val Masks'),\n",
        "                             (TEST_IMAGES, 'Test Images'),\n",
        "                             (TEST_MASKS, 'Test Masks')]:\n",
        "    if os.path.exists(dir_path):\n",
        "        file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
        "        print(f\"✓ {dir_name}: {file_count} files\")\n",
        "    else:\n",
        "        print(f\"✗ {dir_name}: NOT FOUND!\")\n",
        "\n",
        "# UPGRADE 3: Enhanced hyperparameters for accuracy improvement\n",
        "IMG_HEIGHT = 256  # Increased from 128 for better feature extraction\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 3\n",
        "BATCH_SIZE = 8  # Optimized for T4 GPU (16GB)\n",
        "EPOCHS = 30  # Increased from 50 to allow more training time\n",
        "LEARNING_RATE = 0.0001  # Lower for fine-tuning\n",
        "TRAINING_SUBSET = 1.0  # Use full dataset for max accuracy\n",
        "WARMUP_EPOCHS = 5  # Gradual warmup prevents early instability\n",
        "\n",
        "# IMPORTANT: Set this to True to DISABLE early stopping completely\n",
        "# Useful when you want guaranteed full training\n",
        "DISABLE_EARLY_STOPPING = False  # Change to True to train all 60 epochs\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "os.makedirs('visualizations', exist_ok=True)\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENHANCED CONFIGURATION FOR 95-96% ACCURACY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Image Size: {IMG_HEIGHT}x{IMG_WIDTH} (↑ from 128 for better quality)\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs: {EPOCHS} (increased to allow full convergence)\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Warmup Epochs: {WARMUP_EPOCHS} (gradual start)\")\n",
        "print(f\"Dataset: {TRAINING_SUBSET*100}% (Full dataset)\")\n",
        "print(f\"Mixed Precision: Enabled\")\n",
        "print(f\"GPU Memory Growth: Enabled\")\n",
        "print(\"\\n✓ ANTI-EARLY-STOP MEASURES:\")\n",
        "print(f\"  • 20 epoch patience (allows plateau escape)\")\n",
        "print(f\"  • Monitoring Dice (not loss - more stable)\")\n",
        "print(f\"  • Warmup prevents early instability\")\n",
        "print(f\"  • Gradual LR reduction (7 epoch patience)\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70MYEwwBZbQT"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: ENHANCED DATA LOADING WITH ADVANCED AUGMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "def load_image_paths(image_dir, mask_dir, subset=1.0):\n",
        "    \"\"\"Load image and mask paths\"\"\"\n",
        "    if not os.path.exists(image_dir):\n",
        "        raise FileNotFoundError(f\"Image directory not found: {image_dir}\")\n",
        "    if not os.path.exists(mask_dir):\n",
        "        raise FileNotFoundError(f\"Mask directory not found: {mask_dir}\")\n",
        "\n",
        "    image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))])\n",
        "    mask_files = sorted([f for f in os.listdir(mask_dir) if f.lower().endswith('.png')])\n",
        "\n",
        "    if subset < 1.0:\n",
        "        n_samples = int(len(image_files) * subset)\n",
        "        indices = random.sample(range(len(image_files)), n_samples)\n",
        "        image_files = [image_files[i] for i in indices]\n",
        "        mask_files = [mask_files[i] for i in indices]\n",
        "\n",
        "    image_paths = [os.path.join(image_dir, f) for f in image_files]\n",
        "    mask_paths = [os.path.join(mask_dir, f) for f in mask_files]\n",
        "\n",
        "    print(f\"Loaded {len(image_paths)} image-mask pairs\")\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "def load_and_preprocess_image(image_path, mask_path, img_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
        "    \"\"\"Load and preprocess image with normalization\"\"\"\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
        "    img = tf.image.resize(img, img_size)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.resize(mask, img_size)\n",
        "    mask = tf.cast(mask, tf.float32) / 255.0\n",
        "    mask = tf.cast(mask > 0.5, tf.float32)\n",
        "\n",
        "    return img, mask\n",
        "\n",
        "# UPGRADE 4: Advanced augmentation for better generalization\n",
        "@tf.function\n",
        "def apply_advanced_augmentation(img, mask):\n",
        "    \"\"\"\n",
        "    Advanced augmentation pipeline:\n",
        "    - Horizontal/Vertical flips\n",
        "    - Rotation\n",
        "    - Brightness/Contrast adjustment\n",
        "    - Small elastic deformations\n",
        "    \"\"\"\n",
        "    # Random horizontal flip\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        img = tf.image.flip_left_right(img)\n",
        "        mask = tf.image.flip_left_right(mask)\n",
        "\n",
        "    # Random vertical flip\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        img = tf.image.flip_up_down(img)\n",
        "        mask = tf.image.flip_up_down(mask)\n",
        "\n",
        "    # Random rotation (90, 180, 270 degrees)\n",
        "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
        "    img = tf.image.rot90(img, k=k)\n",
        "    mask = tf.image.rot90(mask, k=k)\n",
        "\n",
        "    # Random brightness adjustment\n",
        "    img = tf.image.random_brightness(img, max_delta=0.1)\n",
        "\n",
        "    # Random contrast adjustment\n",
        "    img = tf.image.random_contrast(img, lower=0.9, upper=1.1)\n",
        "\n",
        "    # Clip values\n",
        "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
        "\n",
        "    return img, mask\n",
        "\n",
        "def create_dataset(image_paths, mask_paths, batch_size=BATCH_SIZE, augment=False, cache=True):\n",
        "    \"\"\"Create optimized TensorFlow dataset\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "\n",
        "    # Shuffle before loading\n",
        "    if augment:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "\n",
        "    # Load and preprocess\n",
        "    dataset = dataset.map(load_and_preprocess_image,\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Apply augmentation\n",
        "    if augment:\n",
        "        dataset = dataset.map(apply_advanced_augmentation,\n",
        "                             num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Cache for performance\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    # Batch and prefetch\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# VISUALIZATION 1: Dataset Distribution\n",
        "def visualize_dataset_distribution(train_images, val_images, test_images=None):\n",
        "    \"\"\"\n",
        "    OUTPUT: Bar chart showing dataset split\n",
        "    PURPOSE: Verify balanced data distribution\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "    datasets = ['Training', 'Validation']\n",
        "    counts = [len(train_images), len(val_images)]\n",
        "    colors = ['#2ecc71', '#3498db']\n",
        "\n",
        "    if test_images:\n",
        "        datasets.append('Test')\n",
        "        counts.append(len(test_images))\n",
        "        colors.append('#e74c3c')\n",
        "\n",
        "    bars = ax.bar(datasets, counts, color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
        "    ax.set_ylabel('Number of Images', fontweight='bold', fontsize=12)\n",
        "    ax.set_title('Dataset Distribution', fontsize=16, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{int(height)}',\n",
        "                ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/01_dataset_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Visualization 1: Dataset distribution saved\")\n",
        "\n",
        "# VISUALIZATION 2: Sample Images with Masks\n",
        "def visualize_samples(image_paths, mask_paths, n_samples=6):\n",
        "    \"\"\"\n",
        "    OUTPUT: Grid showing original images, masks, and overlays\n",
        "    PURPOSE: Visual inspection of data quality and annotation\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
        "\n",
        "    indices = random.sample(range(len(image_paths)), n_samples)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img = cv2.imread(image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Original\n",
        "        axes[i, 0].imshow(img)\n",
        "        axes[i, 0].set_title('Original Image', fontweight='bold', fontsize=11)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Mask\n",
        "        axes[i, 1].imshow(mask, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth Mask', fontweight='bold', fontsize=11)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Overlay\n",
        "        overlay = img.copy()\n",
        "        overlay[mask > 127] = [255, 0, 0]\n",
        "        blended = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)\n",
        "        axes[i, 2].imshow(blended)\n",
        "        axes[i, 2].set_title('Overlay (Red = Oil Spill)', fontweight='bold', fontsize=11)\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/02_sample_images.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Visualization 2: Sample images saved\")\n",
        "\n",
        "# VISUALIZATION 3: Data Statistics\n",
        "def plot_data_statistics(image_paths, mask_paths, sample_size=200):\n",
        "    \"\"\"\n",
        "    OUTPUT: Multiple statistical plots about dataset\n",
        "    PURPOSE: Understand data characteristics (coverage, intensity, etc.)\n",
        "    \"\"\"\n",
        "    print(f\"Analyzing {min(sample_size, len(image_paths))} samples...\")\n",
        "\n",
        "    spill_coverage = []\n",
        "    brightness = []\n",
        "    contrast = []\n",
        "\n",
        "    for i in range(min(sample_size, len(image_paths))):\n",
        "        img = cv2.imread(image_paths[i], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(mask_paths[i], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        spill_coverage.append(np.sum(mask > 127) / mask.size * 100)\n",
        "        brightness.append(np.mean(img))\n",
        "        contrast.append(np.std(img))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Oil spill coverage\n",
        "    axes[0].hist(spill_coverage, bins=40, color='#e74c3c', edgecolor='black', alpha=0.7)\n",
        "    axes[0].axvline(np.mean(spill_coverage), color='blue', linestyle='--',\n",
        "                    linewidth=2, label=f'Mean: {np.mean(spill_coverage):.2f}%')\n",
        "    axes[0].set_xlabel('Oil Spill Coverage (%)', fontweight='bold', fontsize=11)\n",
        "    axes[0].set_ylabel('Frequency', fontweight='bold', fontsize=11)\n",
        "    axes[0].set_title('Oil Spill Coverage Distribution', fontweight='bold', fontsize=13)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Brightness\n",
        "    axes[1].hist(brightness, bins=40, color='#f39c12', edgecolor='black', alpha=0.7)\n",
        "    axes[1].axvline(np.mean(brightness), color='red', linestyle='--',\n",
        "                    linewidth=2, label=f'Mean: {np.mean(brightness):.1f}')\n",
        "    axes[1].set_xlabel('Image Brightness', fontweight='bold', fontsize=11)\n",
        "    axes[1].set_ylabel('Frequency', fontweight='bold', fontsize=11)\n",
        "    axes[1].set_title('Brightness Distribution', fontweight='bold', fontsize=13)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Contrast\n",
        "    axes[2].hist(contrast, bins=40, color='#9b59b6', edgecolor='black', alpha=0.7)\n",
        "    axes[2].axvline(np.mean(contrast), color='red', linestyle='--',\n",
        "                    linewidth=2, label=f'Mean: {np.mean(contrast):.1f}')\n",
        "    axes[2].set_xlabel('Image Contrast (Std Dev)', fontweight='bold', fontsize=11)\n",
        "    axes[2].set_ylabel('Frequency', fontweight='bold', fontsize=11)\n",
        "    axes[2].set_title('Contrast Distribution', fontweight='bold', fontsize=13)\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/03_data_statistics.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Visualization 3: Data statistics saved\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA LOADING AND PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "train_images, train_masks = load_image_paths(TRAIN_IMAGES, TRAIN_MASKS, subset=TRAINING_SUBSET)\n",
        "val_images, val_masks = load_image_paths(VAL_IMAGES, VAL_MASKS, subset=TRAINING_SUBSET)\n",
        "test_images, test_masks = load_image_paths(TEST_IMAGES, TEST_MASKS, subset=1.0)\n",
        "\n",
        "print(f\"\\nTraining: {len(train_images)} samples\")\n",
        "print(f\"Validation: {len(val_images)} samples\")\n",
        "print(f\"Test: {len(test_images)} samples\")\n",
        "\n",
        "# Generate visualizations\n",
        "visualize_dataset_distribution(train_images, val_images, test_images)\n",
        "visualize_samples(train_images, train_masks, n_samples=6)\n",
        "plot_data_statistics(train_images, train_masks, sample_size=200)\n",
        "\n",
        "# Create datasets\n",
        "print(\"\\nCreating TensorFlow datasets...\")\n",
        "train_dataset = create_dataset(train_images, train_masks, augment=True)\n",
        "val_dataset = create_dataset(val_images, val_masks, augment=False)\n",
        "test_dataset = create_dataset(test_images, test_masks, augment=False)\n",
        "print(\"✓ Datasets created with advanced augmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQQY0kA9Zlpn"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: ENHANCED U-NET WITH ATTENTION AND RESIDUAL CONNECTIONS\n",
        "# ============================================================================\n",
        "\n",
        "# UPGRADE 5: Fixed Attention mechanism for better feature focus\n",
        "def attention_block(x, g, inter_channel):\n",
        "    \"\"\"\n",
        "    Attention gate for U-Net\n",
        "    Helps model focus on relevant features\n",
        "    FIXED: Properly handles shape matching between encoder and decoder\n",
        "    \"\"\"\n",
        "    # Get the dimensions\n",
        "    theta_x = layers.Conv2D(inter_channel, 1, strides=1, padding='same')(x)\n",
        "    phi_g = layers.Conv2D(inter_channel, 1, strides=1, padding='same')(g)\n",
        "\n",
        "    # Upsample g to match x dimensions if needed\n",
        "    if x.shape[1] != g.shape[1]:\n",
        "        phi_g = layers.UpSampling2D(size=(2, 2))(phi_g)\n",
        "\n",
        "    add_xg = layers.Add()([theta_x, phi_g])\n",
        "    act_xg = layers.Activation('relu')(add_xg)\n",
        "\n",
        "    psi = layers.Conv2D(1, 1, padding='same')(act_xg)\n",
        "    psi = layers.Activation('sigmoid')(psi)\n",
        "\n",
        "    # Multiply attention map with input features\n",
        "    y = layers.Multiply()([x, psi])\n",
        "\n",
        "    # Output conv to match channel dimensions\n",
        "    y = layers.Conv2D(inter_channel, 1, padding='same')(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "# UPGRADE 6: Residual connections for better gradient flow\n",
        "def residual_conv_block(inputs, num_filters, use_dropout=False):\n",
        "    \"\"\"\n",
        "    Residual convolutional block\n",
        "    Prevents vanishing gradients, enables deeper networks\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(num_filters, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(num_filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Residual connection\n",
        "    if inputs.shape[-1] == num_filters:\n",
        "        shortcut = inputs\n",
        "    else:\n",
        "        shortcut = layers.Conv2D(num_filters, 1, padding='same')(inputs)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters, use_dropout=False):\n",
        "    \"\"\"Enhanced encoder with residual connections\"\"\"\n",
        "    x = residual_conv_block(inputs, num_filters, use_dropout)\n",
        "    p = layers.MaxPooling2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters, use_attention=True):\n",
        "    \"\"\"\n",
        "    Enhanced decoder with attention gates\n",
        "    FIXED: Proper attention implementation\n",
        "    \"\"\"\n",
        "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
        "\n",
        "    if use_attention:\n",
        "        # Apply attention to skip connection before concatenation\n",
        "        skip_features = attention_block(skip_features, x, num_filters)\n",
        "\n",
        "    x = layers.Concatenate()([x, skip_features])\n",
        "    x = residual_conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_enhanced_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    \"\"\"\n",
        "    Enhanced U-Net Architecture:\n",
        "    - Deeper network (4 levels)\n",
        "    - Residual connections\n",
        "    - Attention gates\n",
        "    - Dropout for regularization\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Encoder (Downsampling path)\n",
        "    s1, p1 = encoder_block(inputs, 64, use_dropout=False)\n",
        "    s2, p2 = encoder_block(p1, 128, use_dropout=True)\n",
        "    s3, p3 = encoder_block(p2, 256, use_dropout=True)\n",
        "    s4, p4 = encoder_block(p3, 512, use_dropout=True)\n",
        "\n",
        "    # Bridge (Bottleneck)\n",
        "    bridge = residual_conv_block(p4, 1024, use_dropout=True)\n",
        "\n",
        "    # Decoder (Upsampling path with attention)\n",
        "    d1 = decoder_block(bridge, s4, 512, use_attention=True)\n",
        "    d2 = decoder_block(d1, s3, 256, use_attention=True)\n",
        "    d3 = decoder_block(d2, s2, 128, use_attention=True)\n",
        "    d4 = decoder_block(d3, s1, 64, use_attention=True)\n",
        "\n",
        "    # Output layer (float32 for mixed precision)\n",
        "    outputs = layers.Conv2D(1, 1, padding='same', activation='sigmoid', dtype='float32')(d4)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name='Enhanced-Attention-UNet')\n",
        "    return model\n",
        "\n",
        "# UPGRADE 7: Combined loss function for better segmentation\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Dice coefficient metric\n",
        "    Measures overlap between prediction and ground truth\n",
        "    \"\"\"\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    \"\"\"Dice loss = 1 - Dice coefficient\"\"\"\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Combined loss = Binary Cross-Entropy + Dice Loss\n",
        "    BCE handles class imbalance, Dice handles boundary precision\n",
        "    \"\"\"\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return bce + dice\n",
        "\n",
        "def iou_metric(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Intersection over Union (IoU) metric\n",
        "    Standard metric for segmentation tasks\n",
        "    \"\"\"\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL ARCHITECTURE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Build model\n",
        "model = build_enhanced_unet()\n",
        "\n",
        "# Compile with enhanced metrics\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=LEARNING_RATE, weight_decay=0.0001),\n",
        "    loss=combined_loss,\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        dice_coefficient,\n",
        "        iou_metric,\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Count parameters\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"\\n✓ Total parameters: {trainable_params:,}\")\n",
        "print(f\"✓ Architecture: 4-level U-Net with Attention + Residual\")\n",
        "print(f\"✓ Loss: Combined (BCE + Dice)\")\n",
        "print(f\"✓ Metrics: Accuracy, Dice, IoU, Precision, Recall\")\n",
        "\n",
        "# VISUALIZATION 4: Model Architecture Summary (text-based)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL ARCHITECTURE SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try to plot model, but skip if it fails (complex models can crash graphviz)\n",
        "try:\n",
        "    from tensorflow.keras.utils import plot_model\n",
        "    plot_model(model, to_file='visualizations/04_model_architecture.png',\n",
        "               show_shapes=True, show_layer_names=False, dpi=100)\n",
        "    print(\"✓ Visualization 4: Model architecture diagram saved\")\n",
        "except Exception as e:\n",
        "    print(\"⚠ Model diagram skipped (model too complex for visualization)\")\n",
        "    print(\"  Using text summary instead...\")\n",
        "\n",
        "    # Create a simple layer count visualization instead\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    layer_types = {}\n",
        "    for layer in model.layers:\n",
        "        layer_type = layer.__class__.__name__\n",
        "        layer_types[layer_type] = layer_types.get(layer_type, 0) + 1\n",
        "\n",
        "    # Plot layer distribution\n",
        "    types = list(layer_types.keys())\n",
        "    counts = list(layer_types.values())\n",
        "    colors = plt.cm.Set3(range(len(types)))\n",
        "\n",
        "    bars = ax.barh(types, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    ax.set_xlabel('Number of Layers', fontweight='bold', fontsize=12)\n",
        "    ax.set_title('Model Layer Distribution', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    for i, bar in enumerate(bars):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                f' {int(width)}', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('visualizations/04_model_layer_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Visualization 4: Model layer distribution saved (alternative)\")\n",
        "\n",
        "# Print detailed architecture info\n",
        "print(\"\\nArchitecture Details:\")\n",
        "print(f\"  • Input Shape: {IMG_HEIGHT}x{IMG_WIDTH}x{IMG_CHANNELS}\")\n",
        "print(f\"  • Output Shape: {IMG_HEIGHT}x{IMG_WIDTH}x1 (binary mask)\")\n",
        "print(f\"  • Encoder Levels: 4 (64→128→256→512 filters)\")\n",
        "print(f\"  • Bridge: 1024 filters\")\n",
        "print(f\"  • Decoder Levels: 4 with attention gates\")\n",
        "print(f\"  • Skip Connections: Yes (with attention)\")\n",
        "print(f\"  • Residual Blocks: Yes (all conv blocks)\")\n",
        "print(f\"  • Dropout: Yes (encoder levels 2-4)\")\n",
        "print(f\"  • Total Layers: {len(model.layers)}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP6yE3uKZ5F6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 5: TRAINING WITH ADVANCED CALLBACKS\n",
        "# ============================================================================\n",
        "\n",
        "# UPGRADE 8: Enhanced callbacks with MORE PATIENT early stopping\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models/best_model.h5',\n",
        "    monitor='val_dice_coefficient',  # Monitor Dice, not loss\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# FIXED: Much more patient early stopping\n",
        "# Patience increased from 10 to 20 epochs\n",
        "# This allows model to escape local minima and continue improving\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_dice_coefficient',  # Monitor performance metric, not loss\n",
        "    patience=20,  # Wait 20 epochs before stopping (was 10)\n",
        "    mode='max',  # We want dice to maximize\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001  # Only stop if no improvement > 0.01%\n",
        ")\n",
        "\n",
        "# More gradual learning rate reduction\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_dice_coefficient',  # Monitor performance metric\n",
        "    mode='max',\n",
        "    factor=0.5,  # Reduce by half\n",
        "    patience=7,  # Wait 7 epochs before reducing (was 5)\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001  # Only reduce if no improvement > 0.01%\n",
        ")\n",
        "\n",
        "tensorboard = TensorBoard(\n",
        "    log_dir='logs',\n",
        "    histogram_freq=1,\n",
        "    write_graph=True\n",
        ")\n",
        "\n",
        "# Custom callback to log learning rate\n",
        "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.learning_rate\n",
        "        if hasattr(lr, 'numpy'):\n",
        "            lr = lr.numpy()\n",
        "        logs['lr'] = lr\n",
        "\n",
        "# Warmup learning rate schedule\n",
        "class WarmupLearningRate(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, initial_lr, target_lr, warmup_epochs):\n",
        "        super().__init__()\n",
        "        self.initial_lr = initial_lr\n",
        "        self.target_lr = target_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if epoch < self.warmup_epochs:\n",
        "            lr = self.initial_lr + (self.target_lr - self.initial_lr) * (epoch / self.warmup_epochs)\n",
        "            self.model.optimizer.learning_rate.assign(lr)\n",
        "            print(f\"\\n[Warmup] Epoch {epoch+1}/{self.warmup_epochs}: LR = {lr:.6f}\")\n",
        "        elif epoch == self.warmup_epochs:\n",
        "            self.model.optimizer.learning_rate.assign(self.target_lr)\n",
        "            print(f\"\\n✓ Warmup complete! LR = {self.target_lr:.6f}\")\n",
        "\n",
        "# Progress monitor\n",
        "class ProgressMonitor(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.best_dice = 0\n",
        "        self.epochs_since_improvement = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_dice = logs.get('val_dice_coefficient', 0)\n",
        "\n",
        "        if current_dice > self.best_dice:\n",
        "            improvement = current_dice - self.best_dice\n",
        "            self.best_dice = current_dice\n",
        "            self.epochs_since_improvement = 0\n",
        "            print(f\"\\n✓ NEW BEST! Val Dice: {current_dice:.4f} (+{improvement:.4f})\")\n",
        "        else:\n",
        "            self.epochs_since_improvement += 1\n",
        "            print(f\"\\n• No improvement for {self.epochs_since_improvement} epochs (Best: {self.best_dice:.4f})\")\n",
        "\n",
        "            if self.epochs_since_improvement >= 15:\n",
        "                print(f\"⚠ WARNING: 15 epochs without improvement. Early stopping in 5 more epochs...\")\n",
        "\n",
        "# Create all callback instances\n",
        "warmup = WarmupLearningRate(\n",
        "    initial_lr=LEARNING_RATE / 10,\n",
        "    target_lr=LEARNING_RATE,\n",
        "    warmup_epochs=WARMUP_EPOCHS\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models/best_model.h5',\n",
        "    monitor='val_dice_coefficient',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_dice_coefficient',\n",
        "    patience=20,\n",
        "    mode='max',\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_dice_coefficient',\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")\n",
        "\n",
        "progress_monitor = ProgressMonitor()\n",
        "lr_logger = LearningRateLogger()\n",
        "\n",
        "# ADD THIS - it was missing:\n",
        "tensorboard = TensorBoard(\n",
        "    log_dir='logs',\n",
        "    histogram_freq=1,\n",
        "    write_graph=True\n",
        ")\n",
        "\n",
        "# Now create callbacks list\n",
        "if DISABLE_EARLY_STOPPING:\n",
        "    callbacks = [warmup, checkpoint, reduce_lr, progress_monitor, lr_logger, tensorboard]\n",
        "    print(\"\\n⚠ EARLY STOPPING DISABLED - Will train all epochs!\")\n",
        "else:\n",
        "    callbacks = [warmup, checkpoint, reduce_lr, progress_monitor, lr_logger, tensorboard, early_stopping]\n",
        "\n",
        "# UPGRADE 10: Progress monitor to track improvement\n",
        "class ProgressMonitor(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Monitors training progress and alerts if model is stuck\n",
        "    Helps identify when early stopping might trigger\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.best_dice = 0\n",
        "        self.epochs_since_improvement = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_dice = logs.get('val_dice_coefficient', 0)\n",
        "\n",
        "        if current_dice > self.best_dice:\n",
        "            improvement = current_dice - self.best_dice\n",
        "            self.best_dice = current_dice\n",
        "            self.epochs_since_improvement = 0\n",
        "            print(f\"\\n✓ NEW BEST! Val Dice: {current_dice:.4f} (+{improvement:.4f})\")\n",
        "        else:\n",
        "            self.epochs_since_improvement += 1\n",
        "            print(f\"\\n• No improvement for {self.epochs_since_improvement} epochs (Best: {self.best_dice:.4f})\")\n",
        "\n",
        "            if self.epochs_since_improvement >= 15:\n",
        "                print(f\"⚠ WARNING: 15 epochs without improvement. Early stopping in 5 more epochs...\")\n",
        "\n",
        "warmup = WarmupLearningRate(\n",
        "    initial_lr=LEARNING_RATE / 10,  # Start at 10% of target\n",
        "    target_lr=LEARNING_RATE,\n",
        "    warmup_epochs=WARMUP_EPOCHS\n",
        ")\n",
        "\n",
        "progress_monitor = ProgressMonitor()\n",
        "\n",
        "lr_logger = LearningRateLogger()\n",
        "\n",
        "# IMPORTANT: Order matters - put early_stopping LAST so other callbacks run first\n",
        "# Conditionally add early stopping based on user preference\n",
        "if DISABLE_EARLY_STOPPING:\n",
        "    callbacks = [warmup, checkpoint, reduce_lr, progress_monitor, lr_logger, tensorboard]\n",
        "    print(\"\\n⚠ EARLY STOPPING DISABLED - Will train all epochs!\")\n",
        "else:\n",
        "    callbacks = [warmup, checkpoint, reduce_lr, progress_monitor, lr_logger, tensorboard, early_stopping]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING CONFIGURATION - OPTIMIZED FOR FULL CONVERGENCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Initial Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Optimizer: AdamW with weight decay\")\n",
        "print(f\"Early Stopping: {'DISABLED (trains all epochs)' if DISABLE_EARLY_STOPPING else 'ENABLED (patient: 20 epochs)'}\")\n",
        "print(\"\\n✓ IMPROVED CALLBACKS (prevents premature stopping):\")\n",
        "print(f\"  1. Warmup: {WARMUP_EPOCHS} epochs (prevents early instability)\")\n",
        "print(f\"  2. ModelCheckpoint: Saves best Dice score\")\n",
        "print(f\"  3. ReduceLR: Patience=7, monitors Dice\")\n",
        "print(f\"  4. Progress Monitor: Tracks improvement trends\")\n",
        "print(f\"  5. LR Logger: Records learning rate changes\")\n",
        "print(f\"  6. TensorBoard: Visual monitoring\")\n",
        "if not DISABLE_EARLY_STOPPING:\n",
        "    print(f\"  7. Early Stopping: Patience=20, monitors Dice, min_delta=0.0001\")\n",
        "print(f\"\\n✓ KEY IMPROVEMENTS TO PREVENT EARLY STOPPING:\")\n",
        "print(f\"  • Warmup prevents early chaos → no premature stopping\")\n",
        "print(f\"  • 20 epoch patience allows plateau escape (was 10)\")\n",
        "print(f\"  • Monitoring Dice instead of loss (more stable)\")\n",
        "print(f\"  • Progress alerts warn 5 epochs before early stop\")\n",
        "print(f\"  • Min delta 0.0001 only stops if truly stuck\")\n",
        "print(f\"  • Set DISABLE_EARLY_STOPPING=True for guaranteed full training\")\n",
        "print(\"\\n✓ WHAT THIS MEANS:\")\n",
        "print(f\"  • Model will NOT stop at half epochs anymore!\")\n",
        "print(f\"  • Can escape plateaus and continue improving\")\n",
        "print(f\"  • LR reduction helps when stuck (not early stop)\")\n",
        "print(f\"  • You get full convergence to 95-96% accuracy\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete!\")\n",
        "\n",
        "# Save final model\n",
        "model.save('models/final_model.h5')\n",
        "print(\"✓ Final model saved\")\n",
        "\n",
        "# VISUALIZATION 5: Training History\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    OUTPUT: Comprehensive training curves\n",
        "    PURPOSE: Monitor training progress and detect overfitting\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    metrics = [\n",
        "        ('loss', 'Loss', 'lower'),\n",
        "        ('accuracy', 'Accuracy', 'upper'),\n",
        "        ('dice_coefficient', 'Dice Coefficient', 'upper'),\n",
        "        ('iou_metric', 'IoU', 'upper'),\n",
        "        ('precision', 'Precision', 'upper'),\n",
        "        ('recall', 'Recall', 'upper')\n",
        "    ]\n",
        "\n",
        "    for idx, (metric, title, best) in enumerate(metrics):\n",
        "        row = idx // 3\n",
        "        col = idx % 3\n",
        "\n",
        "        if metric in history.history:\n",
        "            epochs = range(1, len(history.history[metric]) + 1)\n",
        "\n",
        "            axes[row, col].plot(epochs, history.history[metric],\n",
        "                               'b-o', label='Train', linewidth=2, markersize=4)\n",
        "            axes[row, col].plot(epochs, history.history[f'val_{metric}'],\n",
        "                               'r-s', label='Validation', linewidth=2, markersize=4)\n",
        "\n",
        "            # Mark best value\n",
        "            if best == 'lower':\n",
        "                best_epoch = np.argmin(history.history[f'val_{metric}']) + 1\n",
        "                best_value = min(history.history[f'val_{metric}'])\n",
        "            else:\n",
        "                best_epoch = np.argmax(history.history[f'val_{metric}']) + 1\n",
        "                best_value = max(history.history[f'val_{metric}'])\n",
        "\n",
        "            axes[row, col].scatter([best_epoch], [best_value],\n",
        "                                  color='green', s=100, zorder=5, marker='*',\n",
        "                                  label=f'Best: {best_value:.4f}')\n",
        "\n",
        "            axes[row, col].set_xlabel('Epoch', fontweight='bold')\n",
        "            axes[row, col].set_ylabel(title, fontweight='bold')\n",
        "            axes[row, col].set_title(title, fontsize=13, fontweight='bold')\n",
        "            axes[row, col].legend()\n",
        "            axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/05_training_history.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Visualization 5: Training history saved\")\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# VISUALIZATION 6: Learning Rate Schedule\n",
        "def plot_learning_rate(history):\n",
        "    \"\"\"\n",
        "    OUTPUT: Learning rate changes over epochs\n",
        "    PURPOSE: Verify learning rate reduction is working\n",
        "    \"\"\"\n",
        "    if 'lr' in history.history:\n",
        "        fig, ax = plt.subplots(figsize=(10, 5))\n",
        "        epochs = range(1, len(history.history['lr']) + 1)\n",
        "        ax.plot(epochs, history.history['lr'], 'b-o', linewidth=2, markersize=6)\n",
        "        ax.set_xlabel('Epoch', fontweight='bold', fontsize=12)\n",
        "        ax.set_ylabel('Learning Rate', fontweight='bold', fontsize=12)\n",
        "        ax.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/06_learning_rate.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"✓ Visualization 6: Learning rate schedule saved\")\n",
        "\n",
        "plot_learning_rate(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlwNAfzXaMMA"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: COMPREHENSIVE EVALUATION ON TEST SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print\n",
        "\n",
        "# ============================================================================\n",
        "# CELL: COMPREHENSIVE EVALUATION AND VISUALIZATIONS\n",
        "# Run this after training completes\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING COMPREHENSIVE EVALUATION VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. PREDICTION VISUALIZATIONS WITH OVERLAYS\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_predictions_detailed(model, image_paths, mask_paths, n_samples=8):\n",
        "    \"\"\"\n",
        "    OUTPUT: Grid showing original, ground truth, prediction, confidence map, and overlay\n",
        "    PURPOSE: Visual assessment of model performance\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(n_samples, 5, figsize=(20, 4*n_samples))\n",
        "\n",
        "    indices = random.sample(range(len(image_paths)), min(n_samples, len(image_paths)))\n",
        "\n",
        "    print(f\"\\nGenerating {n_samples} prediction visualizations...\")\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Load image\n",
        "        img = cv2.imread(image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        # Load mask\n",
        "        mask = cv2.imread(mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        # Predict\n",
        "        img_input = img_resized.astype(np.float32) / 255.0\n",
        "        img_input = np.expand_dims(img_input, axis=0)\n",
        "        pred_prob = model.predict(img_input, verbose=0)[0].squeeze()\n",
        "        pred_binary = (pred_prob > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "        # Calculate metrics\n",
        "        mask_binary = (mask_resized > 127).astype(np.uint8)\n",
        "        pred_binary_calc = (pred_binary > 127).astype(np.uint8)\n",
        "\n",
        "        intersection = np.sum(mask_binary * pred_binary_calc)\n",
        "        union = np.sum(mask_binary) + np.sum(pred_binary_calc) - intersection\n",
        "        iou = intersection / (union + 1e-6)\n",
        "        dice = 2 * intersection / (np.sum(mask_binary) + np.sum(pred_binary_calc) + 1e-6)\n",
        "\n",
        "        # 1. Original Image\n",
        "        axes[i, 0].imshow(img_resized)\n",
        "        axes[i, 0].set_title('Original Image', fontweight='bold', fontsize=10)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # 2. Ground Truth\n",
        "        axes[i, 1].imshow(mask_resized, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth', fontweight='bold', fontsize=10)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # 3. Confidence Heatmap\n",
        "        im = axes[i, 2].imshow(pred_prob, cmap='jet', vmin=0, vmax=1)\n",
        "        axes[i, 2].set_title('Confidence Map', fontweight='bold', fontsize=10)\n",
        "        axes[i, 2].axis('off')\n",
        "        plt.colorbar(im, ax=axes[i, 2], fraction=0.046)\n",
        "\n",
        "        # 4. Binary Prediction\n",
        "        axes[i, 3].imshow(pred_binary, cmap='gray')\n",
        "        axes[i, 3].set_title(f'Prediction\\nIoU: {iou:.3f} | Dice: {dice:.3f}',\n",
        "                            fontweight='bold', fontsize=10)\n",
        "        axes[i, 3].axis('off')\n",
        "\n",
        "        # 5. Overlay\n",
        "        overlay = img_resized.copy()\n",
        "        overlay[pred_binary > 127] = [255, 0, 0]  # Red for predicted spill\n",
        "        blended = cv2.addWeighted(img_resized, 0.6, overlay, 0.4, 0)\n",
        "        axes[i, 4].imshow(blended)\n",
        "        axes[i, 4].set_title('Overlay (Red = Detected)', fontweight='bold', fontsize=10)\n",
        "        axes[i, 4].axis('off')\n",
        "\n",
        "    plt.suptitle('Model Predictions with Confidence Maps and Overlays',\n",
        "                 fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/predictions_with_overlays.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Saved: results/predictions_with_overlays.png\")\n",
        "\n",
        "# Generate predictions on validation set\n",
        "visualize_predictions_detailed(model, val_images, val_masks, n_samples=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 2. CONFUSION MATRIX\n",
        "# ============================================================================\n",
        "\n",
        "def plot_confusion_matrix(model, dataset, dataset_name='Validation'):\n",
        "    \"\"\"\n",
        "    OUTPUT: Confusion matrix (absolute and normalized)\n",
        "    PURPOSE: Understand classification performance at pixel level\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating confusion matrix for {dataset_name} set...\")\n",
        "\n",
        "    all_true = []\n",
        "    all_pred = []\n",
        "\n",
        "    for images, masks in dataset:\n",
        "        preds = model.predict(images, verbose=0)\n",
        "\n",
        "        masks_flat = masks.numpy().flatten()\n",
        "        preds_flat = (preds > 0.5).astype(int).flatten()\n",
        "\n",
        "        all_true.extend(masks_flat)\n",
        "        all_pred.extend(preds_flat)\n",
        "\n",
        "    all_true = (np.array(all_true) > 0.5).astype(int)\n",
        "    all_pred = np.array(all_pred)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_true, all_pred)\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Absolute counts\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "                xticklabels=['No Spill', 'Spill'],\n",
        "                yticklabels=['No Spill', 'Spill'],\n",
        "                ax=axes[0], annot_kws={'size': 16, 'weight': 'bold'})\n",
        "    axes[0].set_title(f'{dataset_name} Set - Confusion Matrix (Counts)',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[0].set_ylabel('True Label', fontweight='bold', fontsize=12)\n",
        "    axes[0].set_xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
        "\n",
        "    # Normalized percentages\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Reds', cbar=True,\n",
        "                xticklabels=['No Spill', 'Spill'],\n",
        "                yticklabels=['No Spill', 'Spill'],\n",
        "                ax=axes[1], annot_kws={'size': 16, 'weight': 'bold'})\n",
        "    axes[1].set_title(f'{dataset_name} Set - Confusion Matrix (Normalized)',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[1].set_ylabel('True Label', fontweight='bold', fontsize=12)\n",
        "    axes[1].set_xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/confusion_matrix_{dataset_name.lower()}.png',\n",
        "                dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"✓ Saved: results/confusion_matrix_{dataset_name.lower()}.png\")\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PIXEL-WISE METRICS - {dataset_name.upper()} SET\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Precision:   {precision:.4f} ({precision*100:.2f}%)\")\n",
        "    print(f\"Recall:      {recall:.4f} ({recall*100:.2f}%)\")\n",
        "    print(f\"F1-Score:    {f1:.4f} ({f1*100:.2f}%)\")\n",
        "    print(f\"Specificity: {specificity:.4f} ({specificity*100:.2f}%)\")\n",
        "    print(f\"\\nTrue Positives:  {tp:,}\")\n",
        "    print(f\"True Negatives:  {tn:,}\")\n",
        "    print(f\"False Positives: {fp:,}\")\n",
        "    print(f\"False Negatives: {fn:,}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return cm, {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
        "                'f1': f1, 'specificity': specificity}\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm_val, metrics_val = plot_confusion_matrix(model, val_dataset, 'Validation')\n",
        "\n",
        "# ============================================================================\n",
        "# 3. SEGMENTATION QUALITY HEATMAP\n",
        "# ============================================================================\n",
        "\n",
        "def plot_quality_heatmap(model, image_paths, mask_paths, grid_size=(10, 10)):\n",
        "    \"\"\"\n",
        "    OUTPUT: Heatmap showing IoU scores across multiple samples\n",
        "    PURPOSE: Quick visual overview of model performance distribution\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating quality heatmap ({grid_size[0]}x{grid_size[1]} samples)...\")\n",
        "\n",
        "    n_samples = min(grid_size[0] * grid_size[1], len(image_paths))\n",
        "    iou_matrix = np.zeros(grid_size)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        mask = cv2.imread(mask_paths[i], cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        img_input = img_resized.astype(np.float32) / 255.0\n",
        "        img_input = np.expand_dims(img_input, axis=0)\n",
        "        pred = model.predict(img_input, verbose=0)[0].squeeze()\n",
        "        pred_binary = (pred > 0.5).astype(np.uint8)\n",
        "\n",
        "        mask_binary = (mask_resized > 127).astype(np.uint8)\n",
        "\n",
        "        intersection = np.sum(mask_binary * pred_binary)\n",
        "        union = np.sum(mask_binary) + np.sum(pred_binary) - intersection\n",
        "        iou = intersection / (union + 1e-6)\n",
        "\n",
        "        row = i // grid_size[1]\n",
        "        col = i % grid_size[1]\n",
        "        iou_matrix[row, col] = iou\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 12))\n",
        "\n",
        "    im = ax.imshow(iou_matrix, cmap='RdYlGn', vmin=0, vmax=1, aspect='auto')\n",
        "\n",
        "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('IoU Score', fontweight='bold', fontsize=14)\n",
        "\n",
        "    ax.set_xticks(np.arange(grid_size[1]))\n",
        "    ax.set_yticks(np.arange(grid_size[0]))\n",
        "    ax.set_xticklabels(np.arange(1, grid_size[1]+1))\n",
        "    ax.set_yticklabels(np.arange(1, grid_size[0]+1))\n",
        "\n",
        "    ax.set_xlabel('Sample Column', fontweight='bold', fontsize=13)\n",
        "    ax.set_ylabel('Sample Row', fontweight='bold', fontsize=13)\n",
        "    ax.set_title('Segmentation Quality Heatmap\\n(IoU Scores Across Dataset)',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(grid_size[0]):\n",
        "        for j in range(grid_size[1]):\n",
        "            if iou_matrix[i, j] > 0:\n",
        "                text_color = 'white' if iou_matrix[i, j] < 0.5 else 'black'\n",
        "                ax.text(j, i, f'{iou_matrix[i, j]:.2f}',\n",
        "                       ha=\"center\", va=\"center\", color=text_color,\n",
        "                       fontsize=9, fontweight='bold')\n",
        "\n",
        "    # Add statistics\n",
        "    mean_iou = np.mean(iou_matrix[iou_matrix > 0])\n",
        "    min_iou = np.min(iou_matrix[iou_matrix > 0])\n",
        "    max_iou = np.max(iou_matrix[iou_matrix > 0])\n",
        "\n",
        "    stats_text = f'Mean IoU: {mean_iou:.3f} | Min: {min_iou:.3f} | Max: {max_iou:.3f}'\n",
        "    ax.text(0.5, -0.05, stats_text, ha='center', va='top',\n",
        "            transform=ax.transAxes, fontsize=12, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/quality_heatmap.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Saved: results/quality_heatmap.png\")\n",
        "\n",
        "# Generate quality heatmap\n",
        "plot_quality_heatmap(model, val_images, val_masks, grid_size=(10, 10))\n",
        "\n",
        "# ============================================================================\n",
        "# 4. BEST AND WORST PREDICTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_best_worst(model, image_paths, mask_paths, n_each=5):\n",
        "    \"\"\"\n",
        "    OUTPUT: Side-by-side comparison of best and worst predictions\n",
        "    PURPOSE: Understand where model excels and struggles\n",
        "    \"\"\"\n",
        "    print(f\"\\nAnalyzing best and worst predictions ({n_each} each)...\")\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(min(100, len(image_paths))):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        mask = cv2.imread(mask_paths[i], cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        img_input = img_resized.astype(np.float32) / 255.0\n",
        "        img_input = np.expand_dims(img_input, axis=0)\n",
        "        pred = model.predict(img_input, verbose=0)[0].squeeze()\n",
        "        pred_binary = (pred > 0.5).astype(np.uint8)\n",
        "\n",
        "        mask_binary = (mask_resized > 127).astype(np.uint8)\n",
        "\n",
        "        intersection = np.sum(mask_binary * pred_binary)\n",
        "        union = np.sum(mask_binary) + np.sum(pred_binary) - intersection\n",
        "        iou = intersection / (union + 1e-6)\n",
        "\n",
        "        predictions.append({'index': i, 'iou': iou})\n",
        "\n",
        "    predictions_df = pd.DataFrame(predictions)\n",
        "    predictions_df = predictions_df.sort_values('iou')\n",
        "\n",
        "    worst_indices = predictions_df.head(n_each)['index'].values\n",
        "    best_indices = predictions_df.tail(n_each)['index'].values\n",
        "\n",
        "    fig, axes = plt.subplots(n_each, 8, figsize=(24, 3*n_each))\n",
        "\n",
        "    for i, idx in enumerate(worst_indices):\n",
        "        img = cv2.imread(image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        mask = cv2.imread(mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        img_input = img_resized.astype(np.float32) / 255.0\n",
        "        img_input = np.expand_dims(img_input, axis=0)\n",
        "        pred_prob = model.predict(img_input, verbose=0)[0].squeeze()\n",
        "        pred_binary = (pred_prob > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "        iou = predictions_df[predictions_df['index'] == idx]['iou'].values[0]\n",
        "\n",
        "        # Worst predictions (left half)\n",
        "        axes[i, 0].imshow(img_resized)\n",
        "        axes[i, 0].set_title(f'Worst #{i+1}\\nIoU: {iou:.3f}',\n",
        "                            fontsize=9, fontweight='bold', color='red')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(mask_resized, cmap='gray')\n",
        "        axes[i, 1].set_title('GT', fontsize=9)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(pred_prob, cmap='jet')\n",
        "        axes[i, 2].set_title('Confidence', fontsize=9)\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "        axes[i, 3].imshow(pred_binary, cmap='gray')\n",
        "        axes[i, 3].set_title('Prediction', fontsize=9)\n",
        "        axes[i, 3].axis('off')\n",
        "\n",
        "    for i, idx in enumerate(best_indices):\n",
        "        img = cv2.imread(image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        mask = cv2.imread(mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "        img_input = img_resized.astype(np.float32) / 255.0\n",
        "        img_input = np.expand_dims(img_input, axis=0)\n",
        "        pred_prob = model.predict(img_input, verbose=0)[0].squeeze()\n",
        "        pred_binary = (pred_prob > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "        iou = predictions_df[predictions_df['index'] == idx]['iou'].values[0]\n",
        "\n",
        "        # Best predictions (right half)\n",
        "        axes[i, 4].imshow(img_resized)\n",
        "        axes[i, 4].set_title(f'Best #{i+1}\\nIoU: {iou:.3f}',\n",
        "                            fontsize=9, fontweight='bold', color='green')\n",
        "        axes[i, 4].axis('off')\n",
        "\n",
        "        axes[i, 5].imshow(mask_resized, cmap='gray')\n",
        "        axes[i, 5].set_title('GT', fontsize=9)\n",
        "        axes[i, 5].axis('off')\n",
        "\n",
        "        axes[i, 6].imshow(pred_prob, cmap='jet')\n",
        "        axes[i, 6].set_title('Confidence', fontsize=9)\n",
        "        axes[i, 6].axis('off')\n",
        "\n",
        "        axes[i, 7].imshow(pred_binary, cmap='gray')\n",
        "        axes[i, 7].set_title('Prediction', fontsize=9)\n",
        "        axes[i, 7].axis('off')\n",
        "\n",
        "    plt.suptitle('Best vs Worst Predictions', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/best_worst_predictions.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Saved: results/best_worst_predictions.png\")\n",
        "\n",
        "# Generate best/worst comparison\n",
        "visualize_best_worst(model, val_images, val_masks, n_each=5)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL VISUALIZATIONS COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nGenerated Files:\")\n",
        "print(\"  1. results/predictions_with_overlays.png\")\n",
        "print(\"  2. results/confusion_matrix_validation.png\")\n",
        "print(\"  3. results/quality_heatmap.png\")\n",
        "print(\"  4. results/best_worst_predictions.png\")\n",
        "print(\"\\nYou now have:\")\n",
        "print(\"  ✓ Prediction overlays (red = detected oil spill)\")\n",
        "print(\"  ✓ Confidence heatmaps showing model certainty\")\n",
        "print(\"  ✓ Confusion matrix with pixel-level metrics\")\n",
        "print(\"  ✓ Quality heatmap across 100 samples\")\n",
        "print(\"  ✓ Best/worst case analysis\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
